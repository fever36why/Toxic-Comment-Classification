# Toxic-Comment-Classification
NLP and Deep Learning on Wiki Comments


This project aims to improve online conversation in an intelligent way, by detecting different types of toxicity (threats, obscenity, insults and hate) from a dataset of comments from Wikipedia’s talk page edits.

•	Comments statistics profiling
•	Comments topic feature vectors
•	Word embedding with GLoVe and fastText

1.	Word-level Detection Model with Bidirectional GRU layer
2.	Word-level Detection Model with CNN layer
3.	Character-level Detection Model with LSTM layer

An accurate stacked model with AUC of 0.98, can precisely identify toxic comments and the toxicity types.
